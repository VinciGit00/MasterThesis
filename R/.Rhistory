df$Summer <- ifelse(df$Season == 2, 1, 0)
df$Autumn <- ifelse(df$Season == 3, 1, 0)
df$Winter <- ifelse(df$Season == 4, 1, 0)
# Aggiungi una colonna binaria per il lockdown basata su date specifiche
df$During_Lockdown <- ifelse(df$Lockdown >= as.Date("2020-03-09") & df$Lockdown <= as.Date("2020-05-03"), 1, 0)
# Estrai le colonne rilevanti per il modello
predictors <- df[, c("Spring", "Summer", "Autumn", "Winter", "During_Lockdown")]
# Variabili legate al meteo
WE_variables <- c("WE_temp_2m", "WE_wind_speed_10m_mean", "WE_wind_speed_10m_max", "WE_tot_precipitation", "WE_precipitation_t",
"WE_surface_pressure", "WE_solar_radiation", "WE_rh_min", "WE_rh_mean", "WE_rh_max", "WE_wind_speed_100m_mean",
"WE_wind_speed_100m_max", "WE_blh_layer_max", "WE_blh_layer_min")
# Combina predittori e variabili meteorologiche
all_predictors <- cbind(predictors, df[, WE_variables])
# Risposta (variabile dipendente)
response <- df$AQ_nh3
# Crea un data frame con tutti i predittori
model_data <- as.data.frame(cbind(all_predictors, response))
# Fit del modello di regressione lineare con interazioni
model <- lm(response ~ .^3, data = model_data)
# Visualizza il riassunto del modello
summary(model)
# Calcola i residui del modello
residuals <- residuals(model)
# Calcola la media dei residui
residuals_mean <- mean(residuals)
# Calcola la skewness dei residui
residuals_skewness <- skewness(residuals)
# Calcola la deviazione standard dei residui
residuals_sd <- sd(residuals)
# Calcola la kurtosis dei residui
residuals_kurtosis <- kurtosis(residuals)
# Stampa i risultati
cat("Media dei residui:", residuals_mean, "\n")
cat("Skewness dei residui:", residuals_skewness, "\n")
cat("Deviazione standard dei residui:", residuals_sd, "\n")
cat("Kurtosis dei residui:", residuals_kurtosis, "\n")
# Calcola le previsioni del modello
predictions <- predict(model, newdata = model_data)
# Calcola il RMSE
rmse <- sqrt(mean((predictions - model_data$response)^2))
# Stampa il valore del RMSE
cat("Root Mean Squared Error (RMSE):", rmse, "\n")
# Grafico scatterplot delle previsioni rispetto ai valori effettivi
plot(model_data$response, predictions, main = "Scatterplot previsions vs real values",
xlab = "Real values", ylab = "Previsions", col = "blue", pch = 16)
# Grafico della distribuzione degli errori
hist(model_data$response - predictions, main = "Error distribution",
xlab = "Errors", col = "lightblue", border = "black")
# Utilizza la funzione glmnet per la regressione LASSO
# Converti il dataframe in una matrice
x <- as.matrix(all_predictors)
# Adatta il modello LASSO
lasso_model <- cv.glmnet(x, model_data$response, alpha = 1)
# Trova il valore di lambda ottimale
lambda_min <- lasso_model$lambda.min
# Seleziona le variabili con il lambda ottimale
lasso_selected_variables <- coef(lasso_model, s = lambda_min)
lasso_selected_variables <- lasso_selected_variables[-1]  # Rimuovi l'intercetta
# Ottieni i nomi delle variabili selezionate
selected_variable_names <- names(lasso_selected_variables)[lasso_selected_variables != 0]
# Stampa le variabili selezionate
cat("Variabili selezionate con LASSO regression:\n")
print(selected_variable_names)
# Crea un nuovo dataframe solo con le variabili selezionate
lasso_model_data <- model_data[, c(selected_variable_names, "response")]
# Fit del modello lineare con le sole variabili selezionate
lasso_model_fit <- lm(response ~ ., data = as.data.frame(lasso_model_data))
# Visualizza il riassunto del modello LASSO
summary(lasso_model_fit)
# Stampa le variabili selezionate con LASSO
cat("Variabili selezionate con LASSO regression:\n")
print(selected_variable_names)
df$During_Lockdown <- ifelse(df$Lockdown >= as.Date("2020-03-09") & df$Lockdown <= as.Date("2020-05-03"), 1, 0)
df$During_Lockdown
View(df)
df$Lockdown
# Imposta la directory di lavoro
setwd("~/Github/MasterThesis/R")
# Carica le librerie necessarie
library(em)
library(caret)
library(e1071)
library(moments)
library(glmnet)
# Leggi il file CSV
df <- read.csv("Agrimonia_scaled_Bertonico_for_interactions.csv")
# Rimuovi le righe con valori mancanti
df <- na.omit(df)
# Aggiungi colonne per le stagioni
df$Spring <- ifelse(df$Season == 1, 1, 0)
df$Summer <- ifelse(df$Season == 2, 1, 0)
df$Autumn <- ifelse(df$Season == 3, 1, 0)
df$Winter <- ifelse(df$Season == 4, 1, 0)
# Aggiungi una colonna binaria per il lockdown basata sugli indici di riga
df$During_Lockdown <- ifelse(1:nrow(df) >= 1529 & 1:nrow(df) <= 1584, 1, 0)
# Estrai le colonne rilevanti per il modello
predictors <- df[, c("Spring", "Summer", "Autumn", "Winter", "During_Lockdown")]
# Variabili legate al meteo
WE_variables <- c("WE_temp_2m", "WE_wind_speed_10m_mean", "WE_wind_speed_10m_max", "WE_tot_precipitation", "WE_precipitation_t",
"WE_surface_pressure", "WE_solar_radiation", "WE_rh_min", "WE_rh_mean", "WE_rh_max", "WE_wind_speed_100m_mean",
"WE_wind_speed_100m_max", "WE_blh_layer_max", "WE_blh_layer_min")
# Combina predittori e variabili meteorologiche
all_predictors <- cbind(predictors, df[, WE_variables])
# Risposta (variabile dipendente)
response <- df$AQ_nh3
# Crea un data frame con tutti i predittori
model_data <- as.data.frame(cbind(all_predictors, response))
# Fit del modello di regressione lineare con interazioni
model <- lm(response ~ .^3, data = model_data)
# Visualizza il riassunto del modello
summary(model)
# Calcola i residui del modello
residuals <- residuals(model)
# Calcola la media dei residui
residuals_mean <- mean(residuals)
# Calcola la skewness dei residui
residuals_skewness <- skewness(residuals)
# Calcola la deviazione standard dei residui
residuals_sd <- sd(residuals)
# Calcola la kurtosis dei residui
residuals_kurtosis <- kurtosis(residuals)
# Stampa i risultati
cat("Media dei residui:", residuals_mean, "\n")
cat("Skewness dei residui:", residuals_skewness, "\n")
cat("Deviazione standard dei residui:", residuals_sd, "\n")
cat("Kurtosis dei residui:", residuals_kurtosis, "\n")
# Calcola le previsioni del modello
predictions <- predict(model, newdata = model_data)
# Calcola il RMSE
rmse <- sqrt(mean((predictions - model_data$response)^2))
# Stampa il valore del RMSE
cat("Root Mean Squared Error (RMSE):", rmse, "\n")
# Grafico scatterplot delle previsioni rispetto ai valori effettivi
plot(model_data$response, predictions, main = "Scatterplot previsions vs real values",
xlab = "Real values", ylab = "Previsions", col = "blue", pch = 16)
# Grafico della distribuzione degli errori
hist(model_data$response - predictions, main = "Error distribution",
xlab = "Errors", col = "lightblue", border = "black")
# Utilizza la funzione glmnet per la regressione LASSO
# Converti il dataframe in una matrice
x <- as.matrix(all_predictors)
# Adatta il modello LASSO
lasso_model <- cv.glmnet(x, model_data$response, alpha = 1)
# Trova il valore di lambda ottimale
lambda_min <- lasso_model$lambda.min
# Seleziona le variabili con il lambda ottimale
lasso_selected_variables <- coef(lasso_model, s = lambda_min)
lasso_selected_variables <- lasso_selected_variables[-1]  # Rimuovi l'intercetta
# Ottieni i nomi delle variabili selezionate
selected_variable_names <- names(lasso_selected_variables)[lasso_selected_variables != 0]
# Stampa le variabili selezionate
cat("Variabili selezionate con LASSO regression:\n")
print(selected_variable_names)
# Crea un nuovo dataframe solo con le variabili selezionate
lasso_model_data <- model_data[, c(selected_variable_names, "response")]
# Fit del modello lineare con le sole variabili selezionate
lasso_model_fit <- lm(response ~ ., data = as.data.frame(lasso_model_data))
# Visualizza il riassunto del modello LASSO
summary(lasso_model_fit)
# Stampa le variabili selezionate con LASSO
cat("Variabili selezionate con LASSO regression:\n")
print(selected_variable_names)
df$During_Lockdown
View(df)
colnames(df)
df$During_Lockdown
options(max.print = Inf)
df$During_Lockdown
# Load required libraries
library(glmnet)
library(e1071)
# Set the working directory and read the data
setwd("~/Github/MasterThesis/R")
# Read data
df <- read.csv("Agrimonia_scaled_Bertonico_for_interactions.csv")
# Remove rows with missing values
df <- na.omit(df)
# Select columns of interest
colonne_da_includere <- c("EM_nh3_agr_waste_burn", "EM_nox_traffic", "EM_nox_sum", "EM_so2_sum",
"WE_temp_2m", "WE_wind_speed_10m_mean", "WE_blh_layer_max",
"WE_blh_layer_min", "WE_tot_precipitation", "WE_precipitation_t")
subset <- df[, colonne_da_includere]
# Calculate correlation matrix
subset_correlation_matrix <- cor(subset)
# Find variable pairs with correlation greater than 0.75
correlation_threshold <- 0.75
high_correlation_pairs <- which(abs(subset_correlation_matrix) > correlation_threshold & upper.tri(subset_correlation_matrix, diag = TRUE), arr.ind = TRUE)
# Display variable pairs with high correlation
for (row in 1:nrow(high_correlation_pairs)) {
var1 <- colnames(subset)[high_correlation_pairs[row, 1]]
var2 <- colnames(subset)[high_correlation_pairs[row, 2]]
correlation_value <- subset_correlation_matrix[high_correlation_pairs[row, 1], high_correlation_pairs[row, 2]]
cat(sprintf("Coppia di variabili: %s e %s, Correlazione: %.2f\n", var1, var2, correlation_value))
}
# Create predictor matrix (x_matrix) and response variable (y)
x_matrix <- as.matrix(df[, colonne_da_includere])
y <- df$AQ_nh3
# Cross-validation using cv.glmnet
cv_res <- cv.glmnet(x = x_matrix, y = y, nfolds = 10)
# Plot cross-validated error curve with lambda values
plot(cv_res$lambda, cv_res$cvm, type = "b", xlab = "Lambda", ylab = "Cross-validated Error", log = "x")
# Add a vertical line for the optimal lambda
abline(v = log(cv_res$lambda.min), col = "red", lty = 2)
# Fit the model using cv.glmnet with the optimal lambda
best_model <- glmnet(x_matrix, y, alpha = 1, lambda = cv_res$lambda.min)
# Extract non-zero coefficients
non_zero_coef <- coef(best_model)
# Print variables of the best model with their standard deviations
cat("Variables in the best model with their standard deviations:\n")
for (i in 1:length(non_zero_coef)) {
if (non_zero_coef[i] != 0) {
variable_name <- colnames(x_matrix)[i]
coefficient <- non_zero_coef[i]
std_dev <- sd(df[[variable_name]])
cat(sprintf("%s: %.4f (Standard Deviation: %.4f)\n", variable_name, coefficient, std_dev))
}
}
# Use the fitted model to make predictions on the training data
predictions <- predict(best_model, newx = x_matrix, s = cv_res$lambda.min, type = "response")
# Calculate residuals
residuals <- y - predictions
# Plot the distribution of residuals
hist(residuals, main = "Error Distribution", xlab = "Residuals", col = "lightblue", border = "black")
# Print summary statistics of residuals
cat("Summary Statistics of Residuals:\n")
cat("Mean:", mean(residuals), "\n")
cat("Standard Deviation:", sd(residuals), "\n")
cat("Skewness:", e1071::skewness(residuals), "\n")
cat("Kurtosis:", e1071::kurtosis(residuals), "\n")
# Calculate the Root Mean Squared Error (RMSE)
rmse <- sqrt(mean(residuals^2))
# Print the RMSE
cat(sprintf("\nRoot Mean Squared Error (RMSE): %.4f\n", rmse))
# Calculate standard error
standard_error <- sd(residuals) / sqrt(length(residuals))
# Print standard error
cat("Standard Error:", standard_error, "\n")
# Calculate autocorrelation of residuals
autocorrelation <- acf(residuals, plot = FALSE)$acf[2]
# Print autocorrelation
cat("Autocorrelation of Residuals:", autocorrelation, "\n")
# Load required libraries
library(glmnet)
# Set the working directory and read the data
setwd("~/Github/MasterThesis/R")
df <- read.csv("Agrimonia_scaled_Bertonico_for_interactions.csv")
# Remove rows with missing values
df <- na.omit(df)
# Select columns of interest
colonne_da_includere <- c("EM_nh3_agr_waste_burn", "EM_nox_traffic", "EM_nox_sum", "EM_so2_sum",
"WE_temp_2m", "WE_wind_speed_10m_mean", "WE_blh_layer_max",
"WE_blh_layer_min", "WE_tot_precipitation", "WE_precipitation_t")
subset <- df[, colonne_da_includere]
# Create a matrix with predictor variables
x_matrix <- as.matrix(subset)
# Response variable
y <- df$AQ_nh3
# Perform ridge regression using glmnet
ridge_model <- cv.glmnet(x_matrix, y, alpha = 0)  # alpha = 0 for ridge regression
# Plot the cross-validated mean squared error as a function of lambda
plot(ridge_model)
# Choose the best lambda based on cross-validation
best_lambda <- ridge_model$lambda.min
# Print the coefficients and corresponding variable names for the best lambda
coefficients <- coef(ridge_model, s = best_lambda)
variable_names <- colnames(x_matrix)
cat("Coefficients for the Best Lambda (Ridge):\n")
for (i in 1:length(coefficients)) {
cat(sprintf("%s: %.4f\n", variable_names[i], coefficients[i]))
}
# Print coefficients and corresponding variable names for the best lambda (Ridge) along with standard deviation
cat("Coefficients for the Best Lambda (Ridge):\n")
for (i in 1:length(coefficients)) {
cat(sprintf("%s: %.4f, Standard Deviation: %.4f\n", variable_names[i], coefficients[i], standard_deviations[i]))
}
# Load required libraries
library(glmnet)
# Set the working directory and read the data
setwd("~/Github/MasterThesis/R")
df <- read.csv("Agrimonia_scaled_Bertonico_for_interactions.csv")
# Remove rows with missing values
df <- na.omit(df)
# Select columns of interest
colonne_da_includere <- c("EM_nh3_agr_waste_burn", "EM_nox_traffic", "EM_nox_sum", "EM_so2_sum",
"WE_temp_2m", "WE_wind_speed_10m_mean", "WE_blh_layer_max",
"WE_blh_layer_min", "WE_tot_precipitation", "WE_precipitation_t")
subset <- df[, colonne_da_includere]
# Create a matrix with predictor variables
x_matrix <- as.matrix(subset)
# Response variable
y <- df$AQ_nh3
# Perform ridge regression using glmnet
ridge_model <- cv.glmnet(x_matrix, y, alpha = 0)  # alpha = 0 for ridge regression
# Plot the cross-validated mean squared error as a function of lambda
plot(ridge_model)
# Choose the best lambda based on cross-validation
best_lambda <- ridge_model$lambda.min
# Print the coefficients and corresponding variable names for the best lambda
coefficients <- coef(ridge_model, s = best_lambda)
variable_names <- colnames(x_matrix)
cat("Coefficients for the Best Lambda (Ridge):\n")
for (i in 1:length(coefficients)) {
cat(sprintf("%s: %.4f\n", variable_names[i], coefficients[i]))
}
# Print coefficients and corresponding variable names for the best lambda (Ridge) along with standard deviation
cat("Coefficients for the Best Lambda (Ridge):\n")
for (i in 1:length(coefficients)) {
cat(sprintf("%s: %.4f, Standard Deviation: %.4f\n", variable_names[i], coefficients[i], standard_deviations[i]))
}
# Load required libraries
library(glmnet)
# Set the working directory and read the data
setwd("~/Github/MasterThesis/R")
df <- read.csv("Agrimonia_scaled_Bertonico_for_interactions.csv")
# Remove rows with missing values
df <- na.omit(df)
# Select columns of interest
colonne_da_includere <- c("EM_nh3_agr_waste_burn", "EM_nox_traffic", "EM_nox_sum", "EM_so2_sum",
"WE_temp_2m", "WE_wind_speed_10m_mean", "WE_blh_layer_max",
"WE_blh_layer_min", "WE_tot_precipitation", "WE_precipitation_t")
subset <- df[, colonne_da_includere]
# Create a matrix with predictor variables
x_matrix <- as.matrix(subset)
# Response variable
y <- df$AQ_nh3
# Perform ridge regression using glmnet
ridge_model <- cv.glmnet(x_matrix, y, alpha = 0)  # alpha = 0 for ridge regression
# Choose the best lambda based on cross-validation
best_lambda <- ridge_model$lambda.min
# Predict the response variable using the ridge model
y_pred <- predict(ridge_model, newx = x_matrix, s = best_lambda)
# Calculate residuals
residuals <- y - y_pred
# Calculate autocorrelation of residuals for ridge
autocorrelation_ridge <- acf(residuals, plot = FALSE)$acf[2]
cat("Autocorrelation of Residuals (Ridge):", autocorrelation_ridge, "\n")
# Perform lasso regression using glmnet
lasso_model <- cv.glmnet(x_matrix, y, alpha = 1)  # alpha = 1 for lasso regression
# Choose the best lambda based on cross-validation for lasso
best_lambda_lasso <- lasso_model$lambda.min
# Predict the response variable using the lasso model
y_pred_lasso <- predict(lasso_model, newx = x_matrix, s = best_lambda_lasso)
# Calculate residuals for lasso
residuals_lasso <- y - y_pred_lasso
# Calculate autocorrelation of residuals for lasso
autocorrelation_lasso <- acf(residuals_lasso, plot = FALSE)$acf[2]
cat("Autocorrelation of Residuals (Lasso):", autocorrelation_lasso, "\n")
library(glmnet)
# Set the working directory and read the data
setwd("~/Github/MasterThesis/R")
df <- read.csv("Agrimonia_scaled_Bertonico_for_interactions.csv")
# Remove rows with missing values
df <- na.omit(df)
# Select columns of interest
colonne_da_includere <- c("EM_nh3_agr_waste_burn", "EM_nox_traffic", "EM_nox_sum", "EM_so2_sum",
"WE_temp_2m", "WE_wind_speed_10m_mean", "WE_blh_layer_max",
"WE_blh_layer_min", "WE_tot_precipitation", "WE_precipitation_t")
subset <- df[, colonne_da_includere]
# Create a matrix with predictor variables
x_matrix <- as.matrix(subset)
# Response variable
y <- df$AQ_nh3
# Fit a polynomial regression model
degree <- 2  # You can change this to the desired degree of the polynomial
poly_model <- lm(y ~ poly(x_matrix, degree, raw = TRUE), data = df)
# Perform Lasso regression
lasso_model <- cv.glmnet(x_matrix, y, alpha = 1)  # Use alpha = 1 for Lasso regression
# Plot the cross-validated mean squared error (MSE) against lambda
plot(lasso_model)
# Select the best lambda value based on cross-validated MSE
best_lambda <- lasso_model$lambda.min
# Print the best lambda value
cat(sprintf("\nBest lambda value: %.4f\n", best_lambda))
# Get the coefficients of the selected model
selected_coefs <- coef(lasso_model, s = best_lambda)
# Print the coefficients
print(selected_coefs)
# Get the indices of non-zero coefficients
non_zero_indices <- which(selected_coefs != 0)
# Extract the names of selected covariates
selected_covariates <- colnames(x_matrix)[non_zero_indices]
# Print the selected covariates and their coefficients
cat("\nSelected covariates and their coefficients:\n")
for (i in non_zero_indices) {
coef_value <- selected_coefs[i]
covariate_name <- colnames(x_matrix)[i]
cat(sprintf("%s: %.4f\n", covariate_name, coef_value))
}
cat("\nSelected covariates, their coefficients, and standard deviations:\n")
if (length(non_zero_indices) > 0) {
for (i in non_zero_indices) {
coef_value <- selected_coefs[i]
coef_sd <- lasso_model$se[i]
covariate_name <- colnames(x_matrix)[i]
cat(sprintf("%s: Coefficient=%.4f, Standard deviation=%.4f\n", covariate_name, coef_value, coef_sd))
}
} else {
cat("No non-zero coefficients selected.\n")
}
# Print the names of parameters included in Lasso model
cat("\nNames of parameters included in Lasso model:\n")
print(selected_covariates)
# Make predictions using the selected covariates
x_selected <- x_matrix[, non_zero_indices-1]
lasso_predictions <- predict(poly_model, newdata = as.data.frame(x_selected))
# Calculate residuals
lasso_residuals <- y - lasso_predictions
# Calculate Root Mean Squared Error (RMSE) for Lasso model
lasso_rmse <- sqrt(mean(lasso_residuals^2))
# Print the RMSE for Lasso model
cat(sprintf("\nRoot Mean Squared Error (RMSE) for Lasso model: %.4f\n", lasso_rmse))
# Print all the parameters of the Lasso model
cat("\nParameters of the Lasso model:\n")
print(lasso_model)
# Calculate and print autocorrelation of residuals
autocorr <- acf(lasso_residuals, plot = FALSE)$acf
cat("\nAutocorrelation of residuals:\n")
print(autocorr)
# Imposta la directory di lavoro
setwd("~/Github/MasterThesis/R")
# Carica le librerie necessarie
library(em)
library(caret)
library(e1071)
library(moments)
library(glmnet)
# Leggi il file CSV
df <- read.csv("Agrimonia_scaled_Bertonico_for_interactions.csv")
# Rimuovi le righe con valori mancanti
df <- na.omit(df)
# Aggiungi colonne per le stagioni
df$Spring <- ifelse(df$Season == 1, 1, 0)
df$Summer <- ifelse(df$Season == 2, 1, 0)
df$Autumn <- ifelse(df$Season == 3, 1, 0)
df$Winter <- ifelse(df$Season == 4, 1, 0)
# Aggiungi una colonna binaria per il lockdown basata sugli indici di riga
df$During_Lockdown <- ifelse(1:nrow(df) >= 1529 & 1:nrow(df) <= 1584, 1, 0)
# Estrai le colonne rilevanti per il modello
predictors <- df[, c("Spring", "Summer", "Autumn", "Winter", "During_Lockdown")]
# Variabili legate al meteo
WE_variables <- c("WE_temp_2m", "WE_wind_speed_10m_mean", "WE_wind_speed_10m_max", "WE_tot_precipitation", "WE_precipitation_t",
"WE_surface_pressure", "WE_solar_radiation", "WE_rh_min", "WE_rh_mean", "WE_rh_max", "WE_wind_speed_100m_mean",
"WE_wind_speed_100m_max", "WE_blh_layer_max", "WE_blh_layer_min")
# Combina predittori e variabili meteorologiche
all_predictors <- cbind(predictors, df[, WE_variables])
# Risposta (variabile dipendente)
response <- df$AQ_nh3
# Crea un data frame con tutti i predittori
model_data <- as.data.frame(cbind(all_predictors, response))
# Fit del modello di regressione lineare con interazioni
model <- lm(response ~ .^3, data = model_data)
# Visualizza il riassunto del modello
summary(model)
# Calcola i residui del modello
residuals <- residuals(model)
# Calcola la media dei residui
residuals_mean <- mean(residuals)
# Calcola la skewness dei residui
residuals_skewness <- skewness(residuals)
# Calcola la deviazione standard dei residui
residuals_sd <- sd(residuals)
# Calcola la kurtosis dei residui
residuals_kurtosis <- kurtosis(residuals)
# Stampa i risultati
cat("Media dei residui:", residuals_mean, "\n")
cat("Skewness dei residui:", residuals_skewness, "\n")
cat("Deviazione standard dei residui:", residuals_sd, "\n")
cat("Kurtosis dei residui:", residuals_kurtosis, "\n")
# Calcola l'autocorrelazione dei residui
residuals_autocorrelation <- acf(residuals, plot = FALSE)
# Estrai i valori di autocorrelazione
autocorrelation_values <- residuals_autocorrelation$acf
# Stampa i valori di autocorrelazione
cat("Autocorrelazione dei residui:\n")
print(autocorrelation_values)
# Calcola le previsioni del modello
predictions <- predict(model, newdata = model_data)
# Calcola il RMSE
rmse <- sqrt(mean((predictions - model_data$response)^2))
# Stampa il valore del RMSE
cat("Root Mean Squared Error (RMSE):", rmse, "\n")
# Grafico scatterplot delle previsioni rispetto ai valori effettivi
plot(model_data$response, predictions, main = "Scatterplot previsions vs real values",
xlab = "Real values", ylab = "Previsions", col = "blue", pch = 16)
# Grafico della distribuzione degli errori
hist(model_data$response - predictions, main = "Error distribution",
xlab = "Errors", col = "lightblue", border = "black")
# Utilizza la funzione glmnet per la regressione LASSO
# Converti il dataframe in una matrice
x <- as.matrix(all_predictors)
# Adatta il modello LASSO
lasso_model <- cv.glmnet(x, model_data$response, alpha = 1)
# Trova il valore di lambda ottimale
lambda_min <- lasso_model$lambda.min
# Seleziona le variabili con il lambda ottimale
lasso_selected_variables <- coef(lasso_model, s = lambda_min)
lasso_selected_variables <- lasso_selected_variables[-1]  # Rimuovi l'intercetta
# Ottieni i nomi delle variabili selezionate
selected_variable_names <- names(lasso_selected_variables)[lasso_selected_variables != 0]
# Stampa le variabili selezionate
cat("Variabili selezionate con LASSO regression:\n")
print(selected_variable_names)
# Crea un nuovo dataframe solo con le variabili selezionate
lasso_model_data <- model_data[, c(selected_variable_names, "response")]
# Fit del modello lineare con le sole variabili selezionate
lasso_model_fit <- lm(response ~ ., data = as.data.frame(lasso_model_data))
# Visualizza il riassunto del modello LASSO
summary(lasso_model_fit)
# Stampa le variabili selezionate con LASSO
cat("Variabili selezionate con LASSO regression:\n")
print(selected_variable_names)
print(residuals_autocorrelation$acf)
