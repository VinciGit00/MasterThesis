cat(sprintf("Coppia di variabili: %s e %s, Correlazione: %.2f\n", var1, var2, correlation_value))
}
# Create a matrix with two columns (WE_temp_2m and AQ_no2)
x_matrix <- as.matrix(df[, c("EM_nh3_agr_waste_burn","EM_nox_traffic", "EM_nox_sum", "EM_so2_sum",
"WE_temp_2m", "WE_wind_speed_10m_mean", "WE_blh_layer_max",
"WE_blh_layer_min", "WE_tot_precipitation", "WE_precipitation_t")])
# Response variable
y <- df$AQ_nh3
# Cross-validation using cv.glmnet
cv_res <- cv.glmnet(x = x_matrix, y = y, nfolds = 10)
# Plot with glmnet plot function (lambda)
plot(cv_res)
library(glmnet)
setwd("~/Github/MasterThesis/R")
df <- read.csv("Agrimonia_scaled_Bertonico_for_interactions.csv")
df <- na.omit(df)
matrix_correlation <- cor(df);
colonne_da_includere <- c("EM_nh3_agr_waste_burn","EM_nox_traffic", "EM_nox_sum", "EM_so2_sum",
"WE_temp_2m", "WE_wind_speed_10m_mean", "WE_blh_layer_max",
"WE_blh_layer_min", "WE_tot_precipitation", "WE_precipitation_t");
subset <- df[, colonne_da_includere];
subset_correlation_matrix <- cor(subset);
# Trovare le coppie di variabili con correlazione in valore assoluto maggiore di 0.75
correlation_threshold <- 0.75
high_correlation_pairs <- which(abs(subset_correlation_matrix) > correlation_threshold & upper.tri(subset_correlation_matrix, diag = TRUE), arr.ind = TRUE)
# Visualizzare le coppie di variabili con correlazione maggiore di 0.75
for (row in 1:nrow(high_correlation_pairs)) {
var1 <- colnames(subset)[high_correlation_pairs[row, 1]]
var2 <- colnames(subset)[high_correlation_pairs[row, 2]]
correlation_value <- subset_correlation_matrix[high_correlation_pairs[row, 1], high_correlation_pairs[row, 2]]
cat(sprintf("Coppia di variabili: %s e %s, Correlazione: %.2f\n", var1, var2, correlation_value))
}
# Create a matrix with two columns (WE_temp_2m and AQ_no2)
x_matrix <- as.matrix(df[, c("EM_nh3_agr_waste_burn","EM_nox_traffic", "EM_nox_sum", "EM_so2_sum",
"WE_temp_2m", "WE_wind_speed_10m_mean", "WE_blh_layer_max",
"WE_blh_layer_min", "WE_tot_precipitation", "WE_precipitation_t")])
# Response variable
y <- df$AQ_nh3
# Cross-validation using cv.glmnet
cv_res <- cv.glmnet(x = x_matrix, y = y, nfolds = 10)
# Plot with glmnet plot function (lambda)
plot(cv_res)
lmabda_opt=cv_res$lambda.min
library(glmnet)
setwd("~/Github/MasterThesis/R")
df <- read.csv("Agrimonia_scaled_Bertonico_for_interactions.csv")
df <- na.omit(df)
matrix_correlation <- cor(df);
colonne_da_includere <- c("EM_nh3_agr_waste_burn","EM_nox_traffic", "EM_nox_sum", "EM_so2_sum",
"WE_temp_2m", "WE_wind_speed_10m_mean", "WE_blh_layer_max",
"WE_blh_layer_min", "WE_tot_precipitation", "WE_precipitation_t");
subset <- df[, colonne_da_includere];
subset_correlation_matrix <- cor(subset);
# Trovare le coppie di variabili con correlazione in valore assoluto maggiore di 0.75
correlation_threshold <- 0.75
high_correlation_pairs <- which(abs(subset_correlation_matrix) > correlation_threshold & upper.tri(subset_correlation_matrix, diag = TRUE), arr.ind = TRUE)
# Visualizzare le coppie di variabili con correlazione maggiore di 0.75
for (row in 1:nrow(high_correlation_pairs)) {
var1 <- colnames(subset)[high_correlation_pairs[row, 1]]
var2 <- colnames(subset)[high_correlation_pairs[row, 2]]
correlation_value <- subset_correlation_matrix[high_correlation_pairs[row, 1], high_correlation_pairs[row, 2]]
cat(sprintf("Coppia di variabili: %s e %s, Correlazione: %.2f\n", var1, var2, correlation_value))
}
# Create a matrix with two columns (WE_temp_2m and AQ_no2)
x_matrix <- as.matrix(df[, c("EM_nh3_agr_waste_burn","EM_nox_traffic", "EM_nox_sum", "EM_so2_sum",
"WE_temp_2m", "WE_wind_speed_10m_mean", "WE_blh_layer_max",
"WE_blh_layer_min", "WE_tot_precipitation", "WE_precipitation_t")])
# Response variable
y <- df$AQ_nh3
# Cross-validation using cv.glmnet
cv_res <- cv.glmnet(x = x_matrix, y = y, nfolds = 10)
# Plot with glmnet plot function (lambda)
plot(cv_res)
lmabda_opt=cv_res$lambda.min
# Fit the model using cv.glmnet with the optimal lambda
cv_res <- cv.glmnet(x = x_matrix, y = y, nfolds = 10)
best_model <- glmnet(x_matrix, y, alpha = 1, lambda = cv_res$lambda.min)
# Extracting non-zero coefficients
non_zero_coef <- coef(best_model)
# Printing variables of the best model
cat("Variables in the best model:\n")
for (i in 1:length(non_zero_coef)) {
if (non_zero_coef[i] != 0) {
variable_name <- colnames(x_matrix)[i]
coefficient <- non_zero_coef[i]
cat(sprintf("%s: %.4f\n", variable_name, coefficient))
}
}
library(glmnet)
setwd("~/Github/MasterThesis/R")
df <- read.csv("Agrimonia_scaled_Bertonico_for_interactions.csv")
df <- na.omit(df)
matrix_correlation <- cor(df);
colonne_da_includere <- c("EM_nh3_agr_waste_burn","EM_nox_traffic", "EM_nox_sum", "EM_so2_sum",
"WE_temp_2m", "WE_wind_speed_10m_mean", "WE_blh_layer_max",
"WE_blh_layer_min", "WE_tot_precipitation", "WE_precipitation_t");
subset <- df[, colonne_da_includere];
subset_correlation_matrix <- cor(subset);
# Trovare le coppie di variabili con correlazione in valore assoluto maggiore di 0.75
correlation_threshold <- 0.75
high_correlation_pairs <- which(abs(subset_correlation_matrix) > correlation_threshold & upper.tri(subset_correlation_matrix, diag = TRUE), arr.ind = TRUE)
# Visualizzare le coppie di variabili con correlazione maggiore di 0.75
for (row in 1:nrow(high_correlation_pairs)) {
var1 <- colnames(subset)[high_correlation_pairs[row, 1]]
var2 <- colnames(subset)[high_correlation_pairs[row, 2]]
correlation_value <- subset_correlation_matrix[high_correlation_pairs[row, 1], high_correlation_pairs[row, 2]]
cat(sprintf("Coppia di variabili: %s e %s, Correlazione: %.2f\n", var1, var2, correlation_value))
}
# Create a matrix with two columns (WE_temp_2m and AQ_no2)
x_matrix <- as.matrix(df[, c("EM_nh3_agr_waste_burn","EM_nox_traffic", "EM_nox_sum", "EM_so2_sum",
"WE_temp_2m", "WE_wind_speed_10m_mean", "WE_blh_layer_max",
"WE_blh_layer_min", "WE_tot_precipitation", "WE_precipitation_t")])
# Response variable
y <- df$AQ_nh3
# Cross-validation using cv.glmnet
cv_res <- cv.glmnet(x = x_matrix, y = y, nfolds = 10)
# Plot with glmnet plot function (lambda)
plot(cv_res)
# Add a vertical line for the optimal lambda
abline(v = log(cv_res$lambda.min), col = "red", lty = 2)
lambda_opt=cv_res$lambda.min
# Fit the model using cv.glmnet with the optimal lambda
cv_res <- cv.glmnet(x = x_matrix, y = y, nfolds = 10)
best_model <- glmnet(x_matrix, y, alpha = 1, lambda = cv_res$lambda.min)
# Extracting non-zero coefficients
non_zero_coef <- coef(best_model)
# Printing variables of the best model
cat("Variables in the best model:\n")
for (i in 1:length(non_zero_coef)) {
if (non_zero_coef[i] != 0) {
variable_name <- colnames(x_matrix)[i]
coefficient <- non_zero_coef[i]
cat(sprintf("%s: %.4f\n", variable_name, coefficient))
}
}
library(glmnet)
setwd("~/Github/MasterThesis/R")
df <- read.csv("Agrimonia_scaled_Bertonico_for_interactions.csv")
df <- na.omit(df)
matrix_correlation <- cor(df);
colonne_da_includere <- c("EM_nh3_agr_waste_burn","EM_nox_traffic", "EM_nox_sum", "EM_so2_sum",
"WE_temp_2m", "WE_wind_speed_10m_mean", "WE_blh_layer_max",
"WE_blh_layer_min", "WE_tot_precipitation", "WE_precipitation_t");
subset <- df[, colonne_da_includere];
subset_correlation_matrix <- cor(subset);
# Trovare le coppie di variabili con correlazione in valore assoluto maggiore di 0.75
correlation_threshold <- 0.75
high_correlation_pairs <- which(abs(subset_correlation_matrix) > correlation_threshold & upper.tri(subset_correlation_matrix, diag = TRUE), arr.ind = TRUE)
# Visualizzare le coppie di variabili con correlazione maggiore di 0.75
for (row in 1:nrow(high_correlation_pairs)) {
var1 <- colnames(subset)[high_correlation_pairs[row, 1]]
var2 <- colnames(subset)[high_correlation_pairs[row, 2]]
correlation_value <- subset_correlation_matrix[high_correlation_pairs[row, 1], high_correlation_pairs[row, 2]]
cat(sprintf("Coppia di variabili: %s e %s, Correlazione: %.2f\n", var1, var2, correlation_value))
}
# Create a matrix with two columns (WE_temp_2m and AQ_no2)
x_matrix <- as.matrix(df[, c("EM_nh3_agr_waste_burn","EM_nox_traffic", "EM_nox_sum", "EM_so2_sum",
"WE_temp_2m", "WE_wind_speed_10m_mean", "WE_blh_layer_max",
"WE_blh_layer_min", "WE_tot_precipitation", "WE_precipitation_t")])
# Response variable
y <- df$AQ_nh3
# Cross-validation using cv.glmnet
cv_res <- cv.glmnet(x = x_matrix, y = y, nfolds = 10)
# Plot with glmnet plot function (lambda)
plot(cv_res)
# Plot the cross-validated error curve with lambda values
plot(cv_res$lambda, cv_res$cvm, type = "b", xlab = "Lambda", ylab = "Cross-validated Error", log = "x")
# Add a vertical line for the optimal lambda
abline(v = log(cv_res$lambda.min), col = "red", lty = 2)
lambda_opt=cv_res$lambda.min
# Fit the model using cv.glmnet with the optimal lambda
cv_res <- cv.glmnet(x = x_matrix, y = y, nfolds = 10)
best_model <- glmnet(x_matrix, y, alpha = 1, lambda = cv_res$lambda.min)
# Extracting non-zero coefficients
non_zero_coef <- coef(best_model)
# Printing variables of the best model
cat("Variables in the best model:\n")
for (i in 1:length(non_zero_coef)) {
if (non_zero_coef[i] != 0) {
variable_name <- colnames(x_matrix)[i]
coefficient <- non_zero_coef[i]
cat(sprintf("%s: %.4f\n", variable_name, coefficient))
}
}
library(glmnet)
setwd("~/Github/MasterThesis/R")
df <- read.csv("Agrimonia_scaled_Bertonico_for_interactions.csv")
df <- na.omit(df)
matrix_correlation <- cor(df);
colonne_da_includere <- c("EM_nh3_agr_waste_burn","EM_nox_traffic", "EM_nox_sum", "EM_so2_sum",
"WE_temp_2m", "WE_wind_speed_10m_mean", "WE_blh_layer_max",
"WE_blh_layer_min", "WE_tot_precipitation", "WE_precipitation_t");
subset <- df[, colonne_da_includere];
subset_correlation_matrix <- cor(subset);
# Trovare le coppie di variabili con correlazione in valore assoluto maggiore di 0.75
correlation_threshold <- 0.75
high_correlation_pairs <- which(abs(subset_correlation_matrix) > correlation_threshold & upper.tri(subset_correlation_matrix, diag = TRUE), arr.ind = TRUE)
# Visualizzare le coppie di variabili con correlazione maggiore di 0.75
for (row in 1:nrow(high_correlation_pairs)) {
var1 <- colnames(subset)[high_correlation_pairs[row, 1]]
var2 <- colnames(subset)[high_correlation_pairs[row, 2]]
correlation_value <- subset_correlation_matrix[high_correlation_pairs[row, 1], high_correlation_pairs[row, 2]]
cat(sprintf("Coppia di variabili: %s e %s, Correlazione: %.2f\n", var1, var2, correlation_value))
}
# Create a matrix with two columns (WE_temp_2m and AQ_no2)
x_matrix <- as.matrix(df[, c("EM_nh3_agr_waste_burn","EM_nox_traffic", "EM_nox_sum", "EM_so2_sum",
"WE_temp_2m", "WE_wind_speed_10m_mean", "WE_blh_layer_max",
"WE_blh_layer_min", "WE_tot_precipitation", "WE_precipitation_t")])
# Response variable
y <- df$AQ_nh3
# Cross-validation using cv.glmnet
cv_res <- cv.glmnet(x = x_matrix, y = y, nfolds = 10)
# Plot with glmnet plot function (lambda)
plot(cv_res)
# Plot the cross-validated error curve with lambda values
plot(cv_res$lambda, cv_res$cvm, type = "b", xlab = "Lambda", ylab = "Cross-validated Error", log = "x")
# Add a vertical line for the optimal lambda
abline(v = log(cv_res$lambda.min), col = "red", lty = 2)
lambda_opt=cv_res$lambda.min
# Fit the model using cv.glmnet with the optimal lambda
cv_res <- cv.glmnet(x = x_matrix, y = y, nfolds = 10)
best_model <- glmnet(x_matrix, y, alpha = 1, lambda = cv_res$lambda.min)
# Extracting non-zero coefficients
non_zero_coef <- coef(best_model)
# Printing variables of the best model
cat("Variables in the best model:\n")
for (i in 1:length(non_zero_coef)) {
if (non_zero_coef[i] != 0) {
variable_name <- colnames(x_matrix)[i]
coefficient <- non_zero_coef[i]
cat(sprintf("%s: %.4f\n", variable_name, coefficient))
}
}
lambda_opt
# Set the working directory and read the data
setwd("~/Github/MasterThesis/R")
df <- read.csv("Agrimonia_scaled_Bertonico_for_interactions.csv")
# Remove rows with missing values
df <- na.omit(df)
# Select columns of interest
colonne_da_includere <- c("EM_nh3_agr_waste_burn", "EM_nox_traffic", "EM_nox_sum", "EM_so2_sum",
"WE_temp_2m", "WE_wind_speed_10m_mean", "WE_blh_layer_max",
"WE_blh_layer_min", "WE_tot_precipitation", "WE_precipitation_t")
subset <- df[, colonne_da_includere]
# Create a matrix with predictor variables
x_matrix <- as.matrix(subset)
# Response variable
y <- df$AQ_nh3
# Perform ridge regression using glmnet
ridge_model <- cv.glmnet(x_matrix, y, alpha = 0)  # alpha = 0 for ridge regression
# Print the coefficients
print(ridge_model$beta)
# Plot the cross-validated mean squared error as a function of lambda
plot(ridge_model)
# Choose the best lambda based on cross-validation
best_lambda <- ridge_model$lambda.min
# Make predictions using the ridge model with the chosen lambda
predictions <- predict(ridge_model, s = best_lambda, newx = x_matrix)
library(glmnet)
setwd("~/Github/MasterThesis/R")
df <- read.csv("Agrimonia_scaled_Bertonico_for_interactions.csv")
df <- na.omit(df)
matrix_correlation <- cor(df);
colonne_da_includere <- c("EM_nh3_agr_waste_burn","EM_nox_traffic", "EM_nox_sum", "EM_so2_sum",
"WE_temp_2m", "WE_wind_speed_10m_mean", "WE_blh_layer_max",
"WE_blh_layer_min", "WE_tot_precipitation", "WE_precipitation_t");
subset <- df[, colonne_da_includere];
subset_correlation_matrix <- cor(subset);
# Trovare le coppie di variabili con correlazione in valore assoluto maggiore di 0.75
correlation_threshold <- 0.75
high_correlation_pairs <- which(abs(subset_correlation_matrix) > correlation_threshold & upper.tri(subset_correlation_matrix, diag = TRUE), arr.ind = TRUE)
# Visualizzare le coppie di variabili con correlazione maggiore di 0.75
for (row in 1:nrow(high_correlation_pairs)) {
var1 <- colnames(subset)[high_correlation_pairs[row, 1]]
var2 <- colnames(subset)[high_correlation_pairs[row, 2]]
correlation_value <- subset_correlation_matrix[high_correlation_pairs[row, 1], high_correlation_pairs[row, 2]]
cat(sprintf("Coppia di variabili: %s e %s, Correlazione: %.2f\n", var1, var2, correlation_value))
}
# Create a matrix with two columns (WE_temp_2m and AQ_no2)
x_matrix <- as.matrix(df[, c("EM_nh3_agr_waste_burn","EM_nox_traffic", "EM_nox_sum", "EM_so2_sum",
"WE_temp_2m", "WE_wind_speed_10m_mean", "WE_blh_layer_max",
"WE_blh_layer_min", "WE_tot_precipitation", "WE_precipitation_t")])
# Response variable
y <- df$AQ_nh3
library(glmnet)
setwd("~/Github/MasterThesis/R")
df <- read.csv("Agrimonia_scaled_Bertonico_for_interactions.csv")
df <- na.omit(df)
matrix_correlation <- cor(df);
colonne_da_includere <- c("EM_nh3_agr_waste_burn","EM_nox_traffic", "EM_nox_sum", "EM_so2_sum",
"WE_temp_2m", "WE_wind_speed_10m_mean", "WE_blh_layer_max",
"WE_blh_layer_min", "WE_tot_precipitation", "WE_precipitation_t");
subset <- df[, colonne_da_includere];
subset_correlation_matrix <- cor(subset);
# Trovare le coppie di variabili con correlazione in valore assoluto maggiore di 0.75
correlation_threshold <- 0.75
high_correlation_pairs <- which(abs(subset_correlation_matrix) > correlation_threshold & upper.tri(subset_correlation_matrix, diag = TRUE), arr.ind = TRUE)
# Visualizzare le coppie di variabili con correlazione maggiore di 0.75
for (row in 1:nrow(high_correlation_pairs)) {
var1 <- colnames(subset)[high_correlation_pairs[row, 1]]
var2 <- colnames(subset)[high_correlation_pairs[row, 2]]
correlation_value <- subset_correlation_matrix[high_correlation_pairs[row, 1], high_correlation_pairs[row, 2]]
cat(sprintf("Coppia di variabili: %s e %s, Correlazione: %.2f\n", var1, var2, correlation_value))
}
# Create a matrix with two columns (WE_temp_2m and AQ_no2)
x_matrix <- as.matrix(df[, c("EM_nh3_agr_waste_burn","EM_nox_traffic", "EM_nox_sum", "EM_so2_sum",
"WE_temp_2m", "WE_wind_speed_10m_mean", "WE_blh_layer_max",
"WE_blh_layer_min", "WE_tot_precipitation", "WE_precipitation_t")])
# Response variable
y <- df$AQ_nh3
# Cross-validation using cv.glmnet
cv_res <- cv.glmnet(x = x_matrix, y = y, nfolds = 10)
# Plot with glmnet plot function (lambda)
plot(cv_res)
# Plot the cross-validated error curve with lambda values
plot(cv_res$lambda, cv_res$cvm, type = "b", xlab = "Lambda", ylab = "Cross-validated Error", log = "x")
# Add a vertical line for the optimal lambda
abline(v = log(cv_res$lambda.min), col = "red", lty = 2)
lambda_opt=cv_res$lambda.min
# Fit the model using cv.glmnet with the optimal lambda
cv_res <- cv.glmnet(x = x_matrix, y = y, nfolds = 10)
best_model <- glmnet(x_matrix, y, alpha = 1, lambda = cv_res$lambda.min)
# Extracting non-zero coefficients
non_zero_coef <- coef(best_model)
# Printing variables of the best model
cat("Variables in the best model:\n")
for (i in 1:length(non_zero_coef)) {
if (non_zero_coef[i] != 0) {
variable_name <- colnames(x_matrix)[i]
coefficient <- non_zero_coef[i]
cat(sprintf("%s: %.4f\n", variable_name, coefficient))
}
}
# Set the working directory and read the data
setwd("~/Github/MasterThesis/R")
df <- read.csv("Agrimonia_scaled_Bertonico_for_interactions.csv")
# Remove rows with missing values
df <- na.omit(df)
# Select columns of interest
colonne_da_includere <- c("EM_nh3_agr_waste_burn", "EM_nox_traffic", "EM_nox_sum", "EM_so2_sum",
"WE_temp_2m", "WE_wind_speed_10m_mean", "WE_blh_layer_max",
"WE_blh_layer_min", "WE_tot_precipitation", "WE_precipitation_t")
subset <- df[, colonne_da_includere]
# Create a matrix with predictor variables
x_matrix <- as.matrix(subset)
# Response variable
y <- df$AQ_nh3
# Perform ridge regression using glmnet
ridge_model <- cv.glmnet(x_matrix, y, alpha = 0)  # alpha = 0 for ridge regression
# Print the coefficients and corresponding variable names
coefficients <- coef(ridge_model, s = best_lambda)
variable_names <- colnames(x_matrix)
cat("Coefficients and Variable Names:\n")
for (i in 1:length(coefficients)) {
cat(sprintf("%s: %.4f\n", variable_names[i], coefficients[i]))
}
# Print the coefficients
print(ridge_model$beta)
# Plot the cross-validated mean squared error as a function of lambda
plot(ridge_model)
# Choose the best lambda based on cross-validation
best_lambda <- ridge_model$lambda.min
# Make predictions using the ridge model with the chosen lambda
predictions <- predict(ridge_model, s = best_lambda, newx = x_matrix)
# Set the working directory and read the data
setwd("~/Github/MasterThesis/R")
df <- read.csv("Agrimonia_scaled_Bertonico_for_interactions.csv")
# Remove rows with missing values
df <- na.omit(df)
# Select columns of interest
colonne_da_includere <- c("EM_nh3_agr_waste_burn", "EM_nox_traffic", "EM_nox_sum", "EM_so2_sum",
"WE_temp_2m", "WE_wind_speed_10m_mean", "WE_blh_layer_max",
"WE_blh_layer_min", "WE_tot_precipitation", "WE_precipitation_t")
subset <- df[, colonne_da_includere]
# Create a matrix with predictor variables
x_matrix <- as.matrix(subset)
# Response variable
y <- df$AQ_nh3
# Perform ridge regression using glmnet
ridge_model <- cv.glmnet(x_matrix, y, alpha = 0)  # alpha = 0 for ridge regression
# Plot the cross-validated mean squared error as a function of lambda
plot(ridge_model)
# Choose the best lambda based on cross-validation
best_lambda <- ridge_model$lambda.min
# Print the coefficients and corresponding variable names for the best lambda
coefficients <- coef(ridge_model, s = best_lambda)
variable_names <- colnames(x_matrix)
cat("Coefficients for the Best Lambda:\n")
for (i in 1:length(coefficients)) {
cat(sprintf("%s: %.4f\n", variable_names[i], coefficients[i]))
}
# Set the working directory and read the data
setwd("~/Github/MasterThesis/R")
df <- read.csv("Agrimonia_scaled_Bertonico_for_interactions.csv")
# Remove rows with missing values
df <- na.omit(df)
# Select columns of interest
colonne_da_includere <- c("EM_nh3_agr_waste_burn", "EM_nox_traffic", "EM_nox_sum", "EM_so2_sum",
"WE_temp_2m", "WE_wind_speed_10m_mean", "WE_blh_layer_max",
"WE_blh_layer_min", "WE_tot_precipitation", "WE_precipitation_t")
subset <- df[, colonne_da_includere]
# Create a matrix with predictor variables
x_matrix <- as.matrix(subset)
# Create quadratic polynomial features
degree <- 2
x_matrix_poly <- poly(x_matrix, degree)
# Response variable
y <- df$AQ_nh3
# Perform polynomial regression using glmnet
poly_model <- cv.glmnet(x_matrix_poly, y, alpha = 0)  # alpha = 0 for ridge regression
# Plot the cross-validated mean squared error as a function of lambda
plot(poly_model)
# Choose the best lambda based on cross-validation
best_lambda <- poly_model$lambda.min
# Print the coefficients and corresponding variable names for the best lambda
coefficients <- coef(poly_model, s = best_lambda)
variable_names <- colnames(x_matrix_poly)
cat("Coefficients for the Best Lambda:\n")
for (i in 1:length(coefficients)) {
cat(sprintf("%s: %.4f\n", variable_names[i], coefficients[i]))
}
# Set the working directory and read the data
setwd("~/Github/MasterThesis/R")
df <- read.csv("Agrimonia_scaled_Bertonico_for_interactions.csv")
# Remove rows with missing values
df <- na.omit(df)
# Select columns of interest
colonne_da_includere <- c("EM_nh3_agr_waste_burn", "EM_nox_traffic", "EM_nox_sum", "EM_so2_sum",
"WE_temp_2m", "WE_wind_speed_10m_mean", "WE_blh_layer_max",
"WE_blh_layer_min", "WE_tot_precipitation", "WE_precipitation_t")
subset <- df[, colonne_da_includere]
# Create a matrix with predictor variables
x_matrix <- as.matrix(subset)
# Create quadratic polynomial features
degree <- 2
x_matrix_poly <- poly(x_matrix, degree)
# Response variable
y <- df$AQ_nh3
# Perform polynomial regression using glmnet
poly_model <- cv.glmnet(x_matrix_poly, y, alpha = 0)  # alpha = 0 for ridge regression
# Plot the cross-validated mean squared error as a function of lambda
plot(poly_model)
# Choose the best lambda based on cross-validation
best_lambda <- poly_model$lambda.min
# Print the coefficients and corresponding variable names for the best lambda
coefficients <- coef(poly_model, s = best_lambda)
variable_names <- colnames(x_matrix_poly)
cat("Coefficients for the Best Lambda:\n")
for (i in 1:length(coefficients)) {
cat(sprintf("%s: %.4f\n", variable_names[i], coefficients[i]))
}
# Set the working directory and read the data
setwd("~/Github/MasterThesis/R")
df <- read.csv("Agrimonia_scaled_Bertonico_for_interactions.csv")
# Remove rows with missing values
df <- na.omit(df)
# Select columns of interest
colonne_da_includere <- c("EM_nh3_agr_waste_burn", "EM_nox_traffic", "EM_nox_sum", "EM_so2_sum",
"WE_temp_2m", "WE_wind_speed_10m_mean", "WE_blh_layer_max",
"WE_blh_layer_min", "WE_tot_precipitation", "WE_precipitation_t")
subset <- df[, colonne_da_includere]
# Create a matrix with predictor variables
x_matrix <- as.matrix(subset)
# Response variable
y <- df$AQ_nh3
# Fit a polynomial regression model
degree <- 2  # You can change this to the desired degree of the polynomial
model <- lm(y ~ poly(x_matrix, degree, raw = TRUE), data = df)
# Make predictions for the original data
predictions <- predict(model, newdata = df)
# Plot the results
plot(df$AQ_nh3, predictions, main = "Polynomial Regression", xlab = "Actual AQ_nh3", ylab = "Predicted AQ_nh3")
# Add a line for perfect predictions (y = x)
abline(0, 1, col = "red")
# Print the model summary to see coefficients
summary(model)
# Set the working directory and read the data
setwd("~/Github/MasterThesis/R")
df <- read.csv("Agrimonia_scaled_Bertonico_for_interactions.csv")
# Remove rows with missing values
df <- na.omit(df)
# Select columns of interest
colonne_da_includere <- c("EM_nh3_agr_waste_burn", "EM_nox_traffic", "EM_nox_sum", "EM_so2_sum",
"WE_temp_2m", "WE_wind_speed_10m_mean", "WE_blh_layer_max",
"WE_blh_layer_min", "WE_tot_precipitation", "WE_precipitation_t")
subset <- df[, colonne_da_includere]
# Create a matrix with predictor variables
x_matrix <- as.matrix(subset)
# Response variable
y <- df$AQ_nh3
# Fit a polynomial regression model
degree <- 2  # You can change this to the desired degree of the polynomial
model <- lm(y ~ poly(x_matrix, degree, raw = TRUE), data = df)
# Make predictions for the original data
predictions <- predict(model, newdata = df)
# Plot the time series
par(mfrow = c(2, 1))  # Set up a 2x1 grid for two plots
# Plot actual values
plot(df$AQ_nh3, type = "l", col = "blue", lwd = 2, main = "Actual vs Predicted Time Series",
xlab = "Index", ylab = "AQ_nh3")
lines(predictions, col = "red", lwd = 2)
# Add a legend
legend("topright", legend = c("Actual", "Predicted"), col = c("blue", "red"), lwd = 2)
# Plot residuals
residuals <- df$AQ_nh3 - predictions
plot(residuals, type = "l", col = "green", lwd = 2, main = "Residuals", xlab = "Index", ylab = "Residuals")
# Add a horizontal line at y = 0
abline(h = 0, col = "black", lty = 2)
# Reset the plotting layout
par(mfrow = c(1, 1))
# Print the model summary to see coefficients
summary(model)
