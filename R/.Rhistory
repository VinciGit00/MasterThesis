cat(sprintf("%s: %.4f\n", selected_covariates[i], coefficient))
}
# Set the working directory and read the data
setwd("~/Github/MasterThesis/R")
df <- read.csv("Agrimonia_scaled_Bertonico_for_interactions.csv")
# Remove rows with missing values
df <- na.omit(df)
# Select columns of interest
colonne_da_includere <- c("EM_nh3_agr_waste_burn", "EM_nox_traffic", "EM_nox_sum", "EM_so2_sum",
"WE_temp_2m", "WE_wind_speed_10m_mean", "WE_blh_layer_max",
"WE_blh_layer_min", "WE_tot_precipitation", "WE_precipitation_t")
subset <- df[, colonne_da_includere]
# Create a matrix with predictor variables
x_matrix <- as.matrix(subset)
# Response variable
y <- df$AQ_nh3
# Fit a polynomial regression model
degree <- 2  # You can change this to the desired degree of the polynomial
poly_model <- lm(y ~ poly(x_matrix, degree, raw = TRUE), data = df)
# Perform Lasso regression
lasso_model <- cv.glmnet(x_matrix, y, alpha = 1)  # Use alpha = 1 for Lasso regression
# Plot the cross-validated mean squared error (MSE) against lambda
plot(lasso_model)
# Select the best lambda value based on cross-validated MSE
best_lambda <- lasso_model$lambda.min
# Print the best lambda value
cat(sprintf("\nBest lambda value: %.4f\n", best_lambda))
# Get the coefficients of the selected model
selected_coefs <- coef(lasso_model, s = best_lambda)
# Print the coefficients
print(selected_coefs)
# Get the indices of non-zero coefficients
non_zero_indices <- which(selected_coefs != 0)
# Extract the names of selected covariates
selected_covariates <- colnames(x_matrix)[non_zero_indices]
# Print the selected covariates
cat("\nSelected covariates:\n")
print(selected_covariates)
# Make predictions using the selected covariates
x_selected <- x_matrix[, non_zero_indices-1]
lasso_predictions <- predict(poly_model, newdata = as.data.frame(x_selected))
# Calculate residuals
lasso_residuals <- y - lasso_predictions
# Calculate Root Mean Squared Error (RMSE) for Lasso model
lasso_rmse <- sqrt(mean(lasso_residuals^2))
# Print the RMSE for Lasso model
cat(sprintf("\nRoot Mean Squared Error (RMSE) for Lasso model: %.4f\n", lasso_rmse))
# Set the working directory and read the data
setwd("~/Github/MasterThesis/R")
df <- read.csv("Agrimonia_scaled_Bertonico_for_interactions.csv")
# Remove rows with missing values
df <- na.omit(df)
# Select columns of interest
colonne_da_includere <- c("EM_nh3_agr_waste_burn", "EM_nox_traffic", "EM_nox_sum", "EM_so2_sum",
"WE_temp_2m", "WE_wind_speed_10m_mean", "WE_blh_layer_max",
"WE_blh_layer_min", "WE_tot_precipitation", "WE_precipitation_t")
subset <- df[, colonne_da_includere]
# Create a matrix with predictor variables
x_matrix <- as.matrix(subset)
# Response variable
y <- df$AQ_nh3
# Fit a polynomial regression model
degree <- 2  # You can change this to the desired degree of the polynomial
poly_model <- lm(y ~ poly(x_matrix, degree, raw = TRUE), data = df)
# Perform Lasso regression
lasso_model <- cv.glmnet(x_matrix, y, alpha = 1)  # Use alpha = 1 for Lasso regression
# Plot the cross-validated mean squared error (MSE) against lambda
plot(lasso_model)
# Select the best lambda value based on cross-validated MSE
best_lambda <- lasso_model$lambda.min
# Print the best lambda value
cat(sprintf("\nBest lambda value: %.4f\n", best_lambda))
# Get the coefficients of the selected model
selected_coefs <- coef(lasso_model, s = best_lambda)
# Print the coefficients
print(selected_coefs)
# Get the indices of non-zero coefficients
non_zero_indices <- which(selected_coefs != 0)
# Extract the names of selected covariates
selected_covariates <- colnames(x_matrix)[non_zero_indices]
# Print the selected covariates and their coefficients
cat("\nSelected covariates and their coefficients:\n")
for (i in non_zero_indices) {
coef_value <- selected_coefs[i]
covariate_name <- colnames(x_matrix)[i]
cat(sprintf("%s: %.4f\n", covariate_name, coef_value))
}
# Make predictions using the selected covariates
x_selected <- x_matrix[, non_zero_indices-1]
lasso_predictions <- predict(poly_model, newdata = as.data.frame(x_selected))
# Calculate residuals
lasso_residuals <- y - lasso_predictions
# Calculate Root Mean Squared Error (RMSE) for Lasso model
lasso_rmse <- sqrt(mean(lasso_residuals^2))
# Print the RMSE for Lasso model
cat(sprintf("\nRoot Mean Squared Error (RMSE) for Lasso model: %.4f\n", lasso_rmse))
# Load required libraries
library(glmnet)
# Set the working directory and read the data
setwd("~/Github/MasterThesis/R")
df <- read.csv("Agrimonia_scaled_Bertonico_for_interactions.csv")
# Remove rows with missing values
df <- na.omit(df)
# Select columns of interest
colonne_da_includere <- c("EM_nh3_agr_waste_burn", "EM_nox_traffic", "EM_nox_sum", "EM_so2_sum",
"WE_temp_2m", "WE_wind_speed_10m_mean", "WE_blh_layer_max",
"WE_blh_layer_min", "WE_tot_precipitation", "WE_precipitation_t")
subset <- df[, colonne_da_includere]
# Create a matrix with predictor variables
x_matrix <- as.matrix(subset)
# Response variable
y <- df$AQ_nh3
# Perform ridge regression using glmnet
ridge_model <- cv.glmnet(x_matrix, y, alpha = 0)  # alpha = 0 for ridge regression
# Plot the cross-validated mean squared error as a function of lambda
plot(ridge_model)
# Choose the best lambda based on cross-validation
best_lambda <- ridge_model$lambda.min
# Print the coefficients and corresponding variable names for the best lambda
coefficients <- coef(ridge_model, s = best_lambda)
variable_names <- colnames(x_matrix)
cat("Coefficients for the Best Lambda (Ridge):\n")
for (i in 1:length(coefficients)) {
cat(sprintf("%s: %.4f\n", variable_names[i], coefficients[i]))
}
# Predict the response variable using the ridge model
y_pred <- predict(ridge_model, newx = x_matrix, s = best_lambda)
# Calculate residuals
residuals <- y - y_pred
# Plot the distribution of residuals
hist(residuals, main = "Distribution of Residuals (Ridge)", xlab = "Residuals")
# Print summary statistics of residuals (Ridge)
cat("Summary Statistics of Residuals (Ridge):\n")
summary(residuals)
# Additional summary statistics of residuals (Ridge)
#cat("\nAdditional Summary Statistics of Residuals (Ridge):\n")
#cat(sprintf("Skewness: %.4f\n", skewness(residuals)))
#cat(sprintf("Mean: %.4f\n", mean(residuals)))
#cat(sprintf("Standard Deviation: %.4f\n", sd(residuals)))
#cat(sprintf("Kurtosis: %.4f\n", kurtosis(residuals)))
# Plot predicted vs. real values for ridge
plot(y, y_pred, main = "Predicted vs. Real (Ridge)", xlab = "Real Values", ylab = "Predicted Values", pch = 16, col = "blue")
abline(0, 1, col = "red", lty = 2)
# Print summary statistics of predicted vs. real values (Ridge)
cat("\nSummary Statistics of Predicted vs. Real Values (Ridge):\n")
summary(cbind(Real = y, Predicted = y_pred))
# Calculate the Root Mean Squared Error (RMSE) for ridge
rmse <- sqrt(mean(residuals^2))
# Print the RMSE for ridge
cat(sprintf("\nRoot Mean Squared Error (RMSE) for Ridge: %.4f\n", rmse))
# Perform lasso regression using glmnet
lasso_model <- cv.glmnet(x_matrix, y, alpha = 1)  # alpha = 1 for lasso regression
# Plot the cross-validated mean squared error as a function of lambda
plot(lasso_model)
# Choose the best lambda based on cross-validation for lasso
best_lambda_lasso <- lasso_model$lambda.min
# Print the coefficients and corresponding variable names for the best lambda for lasso
coefficients_lasso <- coef(lasso_model, s = best_lambda_lasso)
variable_names <- colnames(x_matrix)
cat("\nCoefficients for the Best Lambda (Lasso):\n")
for (i in 1:length(coefficients_lasso)) {
cat(sprintf("%s: %.4f\n", variable_names[i], coefficients_lasso[i]))
}
# Predict the response variable using the lasso model
y_pred_lasso <- predict(lasso_model, newx = x_matrix, s = best_lambda_lasso)
# Calculate residuals for lasso
residuals_lasso <- y - y_pred_lasso
# Plot the distribution of residuals for lasso
hist(residuals_lasso, main = "Distribution of Residuals (Lasso)", xlab = "Residuals")
# Print summary statistics of residuals for lasso
cat("Summary Statistics of Residuals (Lasso):\n")
summary(residuals_lasso)
# Additional summary statistics of residuals for lasso
#cat("\nAdditional Summary Statistics of Residuals (Lasso):\n")
#cat(sprintf("Skewness: %.4f\n", skewness(residuals_lasso)))
#cat(sprintf("Mean: %.4f\n", mean(residuals_lasso)))
#cat(sprintf("Standard Deviation: %.4f\n", sd(residuals_lasso)))
#cat(sprintf("Kurtosis: %.4f\n", kurtosis(residuals_lasso)))
# Plot predicted vs. real values for lasso
plot(y, y_pred_lasso, main = "Predicted vs. Real (Lasso)", xlab = "Real Values", ylab = "Predicted Values", pch = 16, col = "blue")
abline(0, 1, col = "red", lty = 2)
# Print summary statistics of predicted vs. real values for lasso
cat("\nSummary Statistics of Predicted vs. Real Values (Lasso):\n")
summary(cbind(Real = y, Predicted = y_pred_lasso))
# Calculate the Root Mean Squared Error (RMSE) for lasso
rmse_lasso <- sqrt(mean(residuals_lasso^2))
# Print the RMSE for lasso
cat(sprintf("\nRoot Mean Squared Error (RMSE) for Lasso: %.4f\n", rmse_lasso))
# Find non-zero coefficients and corresponding variable names for lasso
non_zero_indices <- which(coefficients_lasso != 0)
non_zero_coefficients <- coefficients_lasso[non_zero_indices]
non_zero_variable_names <- variable_names[non_zero_indices]
cat("\nNon-zero Coefficients and Corresponding Variable Names for the Best Lambda (Lasso):\n")
for (i in 1:length(non_zero_coefficients)) {
cat(sprintf("%s: %.4f\n", non_zero_variable_names[i], non_zero_coefficients[i]))
}
# Set the working directory and read the data
setwd("~/Github/MasterThesis/R")
df <- read.csv("Agrimonia_scaled_Bertonico_for_interactions.csv")
# Remove rows with missing values
df <- na.omit(df)
# Select columns of interest
colonne_da_includere <- c("EM_nh3_agr_waste_burn", "EM_nox_traffic", "EM_nox_sum", "EM_so2_sum",
"WE_temp_2m", "WE_wind_speed_10m_mean", "WE_blh_layer_max",
"WE_blh_layer_min", "WE_tot_precipitation", "WE_precipitation_t")
subset <- df[, colonne_da_includere]
# Create a matrix with predictor variables
x_matrix <- as.matrix(subset)
# Response variable
y <- df$AQ_nh3
# Fit a polynomial regression model
degree <- 2  # You can change this to the desired degree of the polynomial
poly_model <- lm(y ~ poly(x_matrix, degree, raw = TRUE), data = df)
# Perform Lasso regression
lasso_model <- cv.glmnet(x_matrix, y, alpha = 1)  # Use alpha = 1 for Lasso regression
# Plot the cross-validated mean squared error (MSE) against lambda
plot(lasso_model)
# Select the best lambda value based on cross-validated MSE
best_lambda <- lasso_model$lambda.min
# Print the best lambda value
cat(sprintf("\nBest lambda value: %.4f\n", best_lambda))
# Get the coefficients of the selected model
selected_coefs <- coef(lasso_model, s = best_lambda)
# Print the coefficients
print(selected_coefs)
# Get the indices of non-zero coefficients
non_zero_indices <- which(selected_coefs != 0)
# Extract the names of selected covariates
selected_covariates <- colnames(x_matrix)[non_zero_indices]
# Print the selected covariates and their coefficients
cat("\nSelected covariates and their coefficients:\n")
for (i in non_zero_indices) {
coef_value <- selected_coefs[i]
covariate_name <- colnames(x_matrix)[i]
cat(sprintf("%s: %.4f\n", covariate_name, coef_value))
}
# Make predictions using the selected covariates
x_selected <- x_matrix[, non_zero_indices-1]
lasso_predictions <- predict(poly_model, newdata = as.data.frame(x_selected))
# Calculate residuals
lasso_residuals <- y - lasso_predictions
# Calculate Root Mean Squared Error (RMSE) for Lasso model
lasso_rmse <- sqrt(mean(lasso_residuals^2))
# Print the RMSE for Lasso model
cat(sprintf("\nRoot Mean Squared Error (RMSE) for Lasso model: %.4f\n", lasso_rmse))
# Set the working directory and read the data
setwd("~/Github/MasterThesis/R")
df <- read.csv("Agrimonia_scaled_Bertonico_for_interactions.csv")
# Remove rows with missing values
df <- na.omit(df)
# Select columns of interest
colonne_da_includere <- c("EM_nh3_agr_waste_burn", "EM_nox_traffic", "EM_nox_sum", "EM_so2_sum",
"WE_temp_2m", "WE_wind_speed_10m_mean", "WE_blh_layer_max",
"WE_blh_layer_min", "WE_tot_precipitation", "WE_precipitation_t")
subset <- df[, colonne_da_includere]
# Create a matrix with predictor variables
x_matrix <- as.matrix(subset)
# Response variable
y <- df$AQ_nh3
# Fit a polynomial regression model
degree <- 2  # You can change this to the desired degree of the polynomial
poly_model <- lm(y ~ poly(x_matrix, degree, raw = TRUE), data = df)
# Perform Lasso regression
lasso_model <- cv.glmnet(x_matrix, y, alpha = 1)  # Use alpha = 1 for Lasso regression
# Plot the cross-validated mean squared error (MSE) against lambda
plot(lasso_model)
# Select the best lambda value based on cross-validated MSE
best_lambda <- lasso_model$lambda.min
# Print the best lambda value
cat(sprintf("\nBest lambda value: %.4f\n", best_lambda))
# Get the coefficients of the selected model
selected_coefs <- coef(lasso_model, s = best_lambda)
# Print the coefficients
print(selected_coefs)
# Get the indices of non-zero coefficients
non_zero_indices <- which(selected_coefs != 0)
# Extract the names of selected covariates
selected_covariates <- colnames(x_matrix)[non_zero_indices]
# Print the selected covariates and their coefficients
cat("\nSelected covariates and their coefficients:\n")
for (i in non_zero_indices) {
coef_value <- selected_coefs[i]
covariate_name <- colnames(x_matrix)[i]
cat(sprintf("%s: %.4f\n", covariate_name, coef_value))
}
# Make predictions using the selected covariates
x_selected <- x_matrix[, non_zero_indices-1]
lasso_predictions <- predict(poly_model, newdata = as.data.frame(x_selected))
# Calculate residuals
lasso_residuals <- y - lasso_predictions
# Calculate Root Mean Squared Error (RMSE) for Lasso model
lasso_rmse <- sqrt(mean(lasso_residuals^2))
# Print the RMSE for Lasso model
cat(sprintf("\nRoot Mean Squared Error (RMSE) for Lasso model: %.4f\n", lasso_rmse))
# Imposta la directory di lavoro
setwd("~/Github/MasterThesis/R")
# Carica le librerie necessarie
library(em)
library(caret)
library(e1071)  # Questa libreria contiene la funzione skewness
library(moments)  # Questa libreria contiene la funzione kurtosis
library(glmnet)
# Leggi il file CSV
df <- read.csv("Agrimonia_scaled_Bertonico_for_interactions.csv")
# Rimuovi le righe con valori mancanti
df <- na.omit(df)
# Aggiungi colonne per le stagioni
df$Spring <- ifelse(df$Season == 1, 1, 0)
df$Summer <- ifelse(df$Season == 2, 1, 0)
df$Autumn <- ifelse(df$Season == 3, 1, 0)
df$Winter <- ifelse(df$Season == 4, 1, 0)
# Aggiungi una colonna binaria per il lockdown basata su date specifiche
df$During_Lockdown <- ifelse(df$Lockdown >= as.Date("2020-03-09") & df$Lockdown <= as.Date("2020-05-03"), 1, 0)
# Estrai le colonne rilevanti per il modello
predictors <- df[, c("Spring", "Summer", "Autumn", "Winter", "During_Lockdown")]
# Variabili legate al meteo
WE_variables <- c("WE_temp_2m", "WE_wind_speed_10m_mean", "WE_wind_speed_10m_max", "WE_tot_precipitation", "WE_precipitation_t",
"WE_surface_pressure", "WE_solar_radiation", "WE_rh_min", "WE_rh_mean", "WE_rh_max", "WE_wind_speed_100m_mean",
"WE_wind_speed_100m_max", "WE_blh_layer_max", "WE_blh_layer_min")
# Combina predittori e variabili meteorologiche
all_predictors <- cbind(predictors, df[, WE_variables])
# Risposta (variabile dipendente)
response <- df$AQ_nh3
# Crea un data frame con tutti i predittori
model_data <- as.data.frame(cbind(all_predictors, response))
# Fit del modello di regressione lineare con interazioni
model <- lm(response ~ .^3, data = model_data)
# Visualizza il riassunto del modello
summary(model)
# Calcola i residui del modello
residuals <- residuals(model)
# Calcola la media dei residui
residuals_mean <- mean(residuals)
# Calcola la skewness dei residui
residuals_skewness <- skewness(residuals)
# Calcola la deviazione standard dei residui
residuals_sd <- sd(residuals)
# Calcola la kurtosis dei residui
residuals_kurtosis <- kurtosis(residuals)
# Stampa i risultati
cat("Media dei residui:", residuals_mean, "\n")
cat("Skewness dei residui:", residuals_skewness, "\n")
cat("Deviazione standard dei residui:", residuals_sd, "\n")
cat("Kurtosis dei residui:", residuals_kurtosis, "\n")
# Calcola le previsioni del modello
predictions <- predict(model, newdata = model_data)
# Calcola il RMSE
rmse <- sqrt(mean((predictions - model_data$response)^2))
# Stampa il valore del RMSE
cat("Root Mean Squared Error (RMSE):", rmse, "\n")
# Grafico scatterplot delle previsioni rispetto ai valori effettivi
plot(model_data$response, predictions, main = "Scatterplot previsions vs real values",
xlab = "Real values", ylab = "Previsions", col = "blue", pch = 16)
# Grafico della distribuzione degli errori
hist(model_data$response - predictions, main = "Error distribution",
xlab = "Errors", col = "lightblue", border = "black")
# Utilizza la funzione glmnet per la regressione LASSO
# Converti il dataframe in una matrice
x <- as.matrix(all_predictors)
# Adatta il modello LASSO
lasso_model <- cv.glmnet(x, model_data$response, alpha = 1)
# Trova il valore di lambda ottimale
lambda_min <- lasso_model$lambda.min
# Seleziona le variabili con il lambda ottimale
lasso_selected_variables <- coef(lasso_model, s = lambda_min)
lasso_selected_variables <- lasso_selected_variables[-1]  # Rimuovi l'intercetta
# Ottieni i nomi delle variabili selezionate
selected_variable_names <- names(lasso_selected_variables)[lasso_selected_variables != 0]
# Stampa le variabili selezionate
cat("Variabili selezionate con LASSO regression:\n")
print(selected_variable_names)
# Crea un nuovo dataframe solo con le variabili selezionate
lasso_model_data <- model_data[, c(selected_variable_names, "response")]
# Fit del modello lineare con le sole variabili selezionate
lasso_model_fit <- lm(response ~ ., data = as.data.frame(lasso_model_data))
# Visualizza il riassunto del modello LASSO
summary(lasso_model_fit)
# Imposta la directory di lavoro
setwd("~/Github/MasterThesis/R")
# Carica le librerie necessarie
library(em)
library(caret)
library(e1071)  # Questa libreria contiene la funzione skewness
library(moments)  # Questa libreria contiene la funzione kurtosis
library(glmnet)
# Leggi il file CSV
df <- read.csv("Agrimonia_scaled_Bertonico_for_interactions.csv")
# Rimuovi le righe con valori mancanti
df <- na.omit(df)
# Aggiungi colonne per le stagioni
df$Spring <- ifelse(df$Season == 1, 1, 0)
df$Summer <- ifelse(df$Season == 2, 1, 0)
df$Autumn <- ifelse(df$Season == 3, 1, 0)
df$Winter <- ifelse(df$Season == 4, 1, 0)
# Aggiungi una colonna binaria per il lockdown basata su date specifiche
df$During_Lockdown <- ifelse(df$Lockdown >= as.Date("2020-03-09") & df$Lockdown <= as.Date("2020-05-03"), 1, 0)
# Estrai le colonne rilevanti per il modello
predictors <- df[, c("Spring", "Summer", "Autumn", "Winter", "During_Lockdown")]
# Variabili legate al meteo
WE_variables <- c("WE_temp_2m", "WE_wind_speed_10m_mean", "WE_wind_speed_10m_max", "WE_tot_precipitation", "WE_precipitation_t",
"WE_surface_pressure", "WE_solar_radiation", "WE_rh_min", "WE_rh_mean", "WE_rh_max", "WE_wind_speed_100m_mean",
"WE_wind_speed_100m_max", "WE_blh_layer_max", "WE_blh_layer_min")
# Combina predittori e variabili meteorologiche
all_predictors <- cbind(predictors, df[, WE_variables])
# Risposta (variabile dipendente)
response <- df$AQ_nh3
# Crea un data frame con tutti i predittori
model_data <- as.data.frame(cbind(all_predictors, response))
# Fit del modello di regressione lineare con interazioni
model <- lm(response ~ .^3, data = model_data)
# Visualizza il riassunto del modello
summary(model)
# Calcola i residui del modello
residuals <- residuals(model)
# Calcola la media dei residui
residuals_mean <- mean(residuals)
# Calcola la skewness dei residui
residuals_skewness <- skewness(residuals)
# Calcola la deviazione standard dei residui
residuals_sd <- sd(residuals)
# Calcola la kurtosis dei residui
residuals_kurtosis <- kurtosis(residuals)
# Stampa i risultati
cat("Media dei residui:", residuals_mean, "\n")
cat("Skewness dei residui:", residuals_skewness, "\n")
cat("Deviazione standard dei residui:", residuals_sd, "\n")
cat("Kurtosis dei residui:", residuals_kurtosis, "\n")
# Calcola le previsioni del modello
predictions <- predict(model, newdata = model_data)
# Calcola il RMSE
rmse <- sqrt(mean((predictions - model_data$response)^2))
# Stampa il valore del RMSE
cat("Root Mean Squared Error (RMSE):", rmse, "\n")
# Grafico scatterplot delle previsioni rispetto ai valori effettivi
plot(model_data$response, predictions, main = "Scatterplot previsions vs real values",
xlab = "Real values", ylab = "Previsions", col = "blue", pch = 16)
# Grafico della distribuzione degli errori
hist(model_data$response - predictions, main = "Error distribution",
xlab = "Errors", col = "lightblue", border = "black")
# Utilizza la funzione glmnet per la regressione LASSO
# Converti il dataframe in una matrice
x <- as.matrix(all_predictors)
# Adatta il modello LASSO
lasso_model <- cv.glmnet(x, model_data$response, alpha = 1)
# Trova il valore di lambda ottimale
lambda_min <- lasso_model$lambda.min
# Seleziona le variabili con il lambda ottimale
lasso_selected_variables <- coef(lasso_model, s = lambda_min)
lasso_selected_variables <- lasso_selected_variables[-1]  # Rimuovi l'intercetta
# Ottieni i nomi delle variabili selezionate
selected_variable_names <- names(lasso_selected_variables)[lasso_selected_variables != 0]
# Stampa le variabili selezionate
cat("Variabili selezionate con LASSO regression:\n")
print(selected_variable_names)
# Crea un nuovo dataframe solo con le variabili selezionate
lasso_model_data <- model_data[, c(selected_variable_names, "response")]
# Fit del modello lineare con le sole variabili selezionate
lasso_model_fit <- lm(response ~ ., data = as.data.frame(lasso_model_data))
# Visualizza il riassunto del modello LASSO
summary(lasso_model_fit)
# Stampa le variabili selezionate con LASSO
cat("Variabili selezionate con LASSO regression:\n")
print(selected_variable_names)
# Set the working directory and read the data
setwd("~/Github/MasterThesis/R")
df <- read.csv("Agrimonia_scaled_Bertonico_for_interactions.csv")
# Remove rows with missing values
df <- na.omit(df)
# Select columns of interest
colonne_da_includere <- c("EM_nh3_agr_waste_burn", "EM_nox_traffic", "EM_nox_sum", "EM_so2_sum",
"WE_temp_2m", "WE_wind_speed_10m_mean", "WE_blh_layer_max",
"WE_blh_layer_min", "WE_tot_precipitation", "WE_precipitation_t")
subset <- df[, colonne_da_includere]
# Create a matrix with predictor variables
x_matrix <- as.matrix(subset)
# Response variable
y <- df$AQ_nh3
# Fit a polynomial regression model
degree <- 2  # You can change this to the desired degree of the polynomial
poly_model <- lm(y ~ poly(x_matrix, degree, raw = TRUE), data = df)
# Perform Lasso regression
lasso_model <- cv.glmnet(x_matrix, y, alpha = 1)  # Use alpha = 1 for Lasso regression
# Plot the cross-validated mean squared error (MSE) against lambda
plot(lasso_model)
# Select the best lambda value based on cross-validated MSE
best_lambda <- lasso_model$lambda.min
# Print the best lambda value
cat(sprintf("\nBest lambda value: %.4f\n", best_lambda))
# Get the coefficients of the selected model
selected_coefs <- coef(lasso_model, s = best_lambda)
# Print the coefficients
print(selected_coefs)
# Get the indices of non-zero coefficients
non_zero_indices <- which(selected_coefs != 0)
# Extract the names of selected covariates
selected_covariates <- colnames(x_matrix)[non_zero_indices]
# Print the selected covariates and their coefficients
cat("\nSelected covariates and their coefficients:\n")
for (i in non_zero_indices) {
coef_value <- selected_coefs[i]
covariate_name <- colnames(x_matrix)[i]
cat(sprintf("%s: %.4f\n", covariate_name, coef_value))
}
# Make predictions using the selected covariates
x_selected <- x_matrix[, non_zero_indices-1]
lasso_predictions <- predict(poly_model, newdata = as.data.frame(x_selected))
# Calculate residuals
lasso_residuals <- y - lasso_predictions
# Calculate Root Mean Squared Error (RMSE) for Lasso model
lasso_rmse <- sqrt(mean(lasso_residuals^2))
# Print the RMSE for Lasso model
cat(sprintf("\nRoot Mean Squared Error (RMSE) for Lasso model: %.4f\n", lasso_rmse))
